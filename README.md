# RAGBot: Retrieval-Augmented Generation for IT Support Tickets

Welcome to **RAGBot** â€” a full-stack chatbot powered by **vector search**, **FAISS**, and a **quantized open-source LLM (Zephyr-7B-Beta)**. It provides **contextual answers** to IT support queries using historical ticket data.

Built entirely in **Google Colab**, optimized for **free-tier infrastructure**, and designed to be fully modular and extensible.

---

## ğŸ“Œ Project Overview

| ğŸ”§ Module        | ğŸ” Description                                                                 |
|------------------|--------------------------------------------------------------------------------|
| ğŸ” Retrieval     | FAISS + SentenceTransformer embeddings to fetch relevant ticket responses      |
| ğŸ§  Generation     | Zephyr-7B-Beta (4-bit quantized) model for empathetic, LLM-generated responses |
| ğŸ“Š Evaluation     | Precision@k metric to evaluate retrieval quality                              |
| ğŸ’¬ Interface      | Command-line or Python-callable function for RAG-based Q&A                   |

---

We use TheBloke/zephyr-7B-beta-GGUF in 4-bit quantized format for efficiency on Colab.

from transformers import AutoTokenizer, AutoModelForCausalLM
tokenizer = AutoTokenizer.from_pretrained(
          "TheBloke/zephyr-7B-beta-GGUF", 
            use_fast=True)
model = AutoModelForCausalLM.from_pretrained(
    "TheBloke/zephyr-7B-beta-GGUF",
    device_map="auto",
    load_in_4bit=True
)

ğŸ› ï¸ TODOs & Improvements
	â€¢	ğŸ” Switch to all-mpnet-base-v2 or e5-large-v2 embeddings
	â€¢	ğŸ” Add BM25 + dense hybrid retrieval
	â€¢	ğŸ§ª Implement BLEU/ROUGE/LlamaIndex eval for generated answers
	â€¢	ğŸŒ Wrap with Gradio for interactive UI
	â€¢	â˜ï¸ Deploy backend to AWS EC2 free tier
